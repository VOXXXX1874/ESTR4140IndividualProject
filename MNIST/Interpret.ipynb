{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import (\n",
    "    show_cam_on_image, deprocess_image, preprocess_image\n",
    ")\n",
    "from torchvision.models import resnet18\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction vector is: tensor([[-6.3110,  5.6962]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "predict result tensor([1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = resnet18(num_classes=2).to(device).eval()\n",
    "model.load_state_dict(torch.load('explicit_label.pkl'))\n",
    "rgb_img = cv2.imread('./noiseImageLabel1.png', 1)[:, :, ::-1]\n",
    "rgb_img = np.float32(rgb_img) / 255\n",
    "input_tensor = preprocess_image(rgb_img,\n",
    "                                mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225]).to(device)\n",
    "print('model prediction vector is:', model(input_tensor))\n",
    "print('predict result',model(input_tensor).argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [model.layer4[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cam_on_image(img: np.ndarray,\n",
    "                      mask: np.ndarray,\n",
    "                      use_rgb: bool = False,\n",
    "                      colormap: int = cv2.COLORMAP_JET,\n",
    "                      image_weight: float = 0.5) -> np.ndarray:\n",
    "    \n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), colormap)\n",
    "    if use_rgb:\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "\n",
    "    if np.max(img) > 1:\n",
    "        raise Exception(\n",
    "            \"The input image should np.float32 in the range [0, 1]\")\n",
    "\n",
    "    if image_weight < 0 or image_weight > 1:\n",
    "        raise Exception(\n",
    "            f\"image_weight should be in the range [0, 1].\\\n",
    "                Got: {image_weight}\")\n",
    "\n",
    "    cam = (1 - image_weight) * heatmap + image_weight * img\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[127 124   0]\n",
      "  [127 124   0]\n",
      "  [127 124   0]\n",
      "  ...\n",
      "  [ 77 127  51]\n",
      "  [ 77 127  51]\n",
      "  [ 77 127  51]]\n",
      "\n",
      " [[127 124   0]\n",
      "  [127 124   0]\n",
      "  [127 124   0]\n",
      "  ...\n",
      "  [ 77 127  51]\n",
      "  [ 77 127  51]\n",
      "  [ 77 127  51]]\n",
      "\n",
      " [[127 124   0]\n",
      "  [127 124   0]\n",
      "  [127 124   0]\n",
      "  ...\n",
      "  [ 77 127  51]\n",
      "  [ 77 127  51]\n",
      "  [ 77 127  51]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[127 116   0]\n",
      "  [127 116   0]\n",
      "  [127 116   0]\n",
      "  ...\n",
      "  [ 29 127  99]\n",
      "  [ 29 127  99]\n",
      "  [ 29 127  99]]\n",
      "\n",
      " [[127 116   0]\n",
      "  [127 116   0]\n",
      "  [127 116   0]\n",
      "  ...\n",
      "  [ 29 127  99]\n",
      "  [ 29 127  99]\n",
      "  [ 29 127  99]]\n",
      "\n",
      " [[127 116   0]\n",
      "  [127 116   0]\n",
      "  [127 116   0]\n",
      "  ...\n",
      "  [ 29 127  99]\n",
      "  [ 29 127  99]\n",
      "  [ 29 127  99]]]\n"
     ]
    }
   ],
   "source": [
    "# CAM object\n",
    "targets = None\n",
    "cam_algorithm = GradCAM\n",
    "with cam_algorithm(model=model,\n",
    "                       target_layers=target_layers) as cam:\n",
    "    cam.batch_size = 32\n",
    "    # Target is for downstream tasks and 281 is for specific class?\n",
    "    \n",
    "    # Why grayscale_cam?\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, \n",
    "                        targets=targets,\n",
    "                        )\n",
    "    # ??\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "    print(visualization)\n",
    "    visualization = cv2.cvtColor(visualization, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./interpretation_GradCam/0.jpg',visualization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
