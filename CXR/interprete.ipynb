{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAMElementWise\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import (\n",
    "    show_cam_on_image, deprocess_image, preprocess_image\n",
    ")\n",
    "from torchvision.models import resnet18\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = resnet18(num_classes=2).to(device).eval()\n",
    "model.load_state_dict(torch.load('best.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model prediction vector is: tensor([[ 2.8403, -2.8671]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "predict result tensor([0], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "file_name = '00024114_000.png'\n",
    "rgb_img = cv2.imread('./task_images_downsampled/train/0/'+file_name, 1)[:, :, ::-1]\n",
    "rgb_img = np.float32(rgb_img) / 255\n",
    "input_tensor = preprocess_image(rgb_img,\n",
    "                                mean=[0.485, 0.456, 0.406],\n",
    "                                std=[0.229, 0.224, 0.225]).to(device)\n",
    "print('model prediction vector is:', model(input_tensor))\n",
    "print('predict result',model(input_tensor).argmax(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_layers = [model.layer4[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cam_on_image(img: np.ndarray,\n",
    "                      mask: np.ndarray,\n",
    "                      use_rgb: bool = False,\n",
    "                      colormap: int = cv2.COLORMAP_JET,\n",
    "                      image_weight: float = 0.5) -> np.ndarray:\n",
    "    \n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), colormap)\n",
    "    if use_rgb:\n",
    "        heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "\n",
    "    if np.max(img) > 1:\n",
    "        raise Exception(\n",
    "            \"The input image should np.float32 in the range [0, 1]\")\n",
    "\n",
    "    if image_weight < 0 or image_weight > 1:\n",
    "        raise Exception(\n",
    "            f\"image_weight should be in the range [0, 1].\\\n",
    "                Got: {image_weight}\")\n",
    "\n",
    "    cam = (1 - image_weight) * heatmap + image_weight * img\n",
    "    cam = cam / np.max(cam)\n",
    "    return np.uint8(255 * cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00617133 0.00617133 0.00617133 ... 0.00332171 0.00332171 0.00332171]\n",
      " [0.00617133 0.00617133 0.00617133 ... 0.00332171 0.00332171 0.00332171]\n",
      " [0.00617133 0.00617133 0.00617133 ... 0.00332171 0.00332171 0.00332171]\n",
      " ...\n",
      " [0.0254899  0.0254899  0.0254899  ... 0.10752687 0.10752687 0.10752687]\n",
      " [0.0254899  0.0254899  0.0254899  ... 0.10752687 0.10752687 0.10752687]\n",
      " [0.0254899  0.0254899  0.0254899  ... 0.10752687 0.10752687 0.10752687]]\n"
     ]
    }
   ],
   "source": [
    "# CAM object\n",
    "#targets = [ClassifierOutputTarget(1)]\n",
    "targets = None\n",
    "cam_algorithm = GradCAMElementWise\n",
    "with cam_algorithm(model=model,\n",
    "                       target_layers=target_layers) as cam:\n",
    "    cam.batch_size = 32\n",
    "    # Target is for downstream tasks and 281 is for specific class?\n",
    "    \n",
    "    # Why grayscale_cam?\n",
    "    grayscale_cam = cam(input_tensor=input_tensor, \n",
    "                        targets=targets,\n",
    "                        )\n",
    "    # ??\n",
    "    grayscale_cam = grayscale_cam[0, :]\n",
    "    print(grayscale_cam)\n",
    "    visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)\n",
    "    visualization = cv2.cvtColor(visualization, cv2.COLOR_RGB2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i in range(0,len(visualization)):\n",
    "#    for j in range(0,len(visualization)):\n",
    "#        visualization[i,j,0] = np.random.normal(loc=128, scale=127) if visualization[i,j,0]>100 else visualization[i,j,0]\n",
    "\n",
    "cv2.imwrite('./interpretation/'+file_name,visualization)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
